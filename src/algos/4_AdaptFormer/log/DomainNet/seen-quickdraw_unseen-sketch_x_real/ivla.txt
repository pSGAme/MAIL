================Parameters Settings=================
Parameters:	Namespace(alpha=0.05, log_name='ivla', num_shots=2, visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.visual_adapter.1.down.0.weight
text_prompt_learner.visual_adapter.1.down.0.bias
text_prompt_learner.visual_adapter.1.up.weight
text_prompt_learner.visual_adapter.1.up.bias
text_prompt_learner.visual_adapter.2.down.0.weight
text_prompt_learner.visual_adapter.2.down.0.bias
text_prompt_learner.visual_adapter.2.up.weight
text_prompt_learner.visual_adapter.2.up.bias
text_prompt_learner.visual_adapter.3.down.0.weight
text_prompt_learner.visual_adapter.3.down.0.bias
text_prompt_learner.visual_adapter.3.up.weight
text_prompt_learner.visual_adapter.3.up.bias
text_prompt_learner.visual_adapter.4.down.0.weight
text_prompt_learner.visual_adapter.4.down.0.bias
text_prompt_learner.visual_adapter.4.up.weight
text_prompt_learner.visual_adapter.4.up.bias
text_prompt_learner.visual_adapter.5.down.0.weight
text_prompt_learner.visual_adapter.5.down.0.bias
text_prompt_learner.visual_adapter.5.up.weight
text_prompt_learner.visual_adapter.5.up.bias
text_prompt_learner.visual_adapter.6.down.0.weight
text_prompt_learner.visual_adapter.6.down.0.bias
text_prompt_learner.visual_adapter.6.up.weight
text_prompt_learner.visual_adapter.6.up.bias
text_prompt_learner.visual_adapter.7.down.0.weight
text_prompt_learner.visual_adapter.7.down.0.bias
text_prompt_learner.visual_adapter.7.up.weight
text_prompt_learner.visual_adapter.7.up.bias
text_prompt_learner.visual_adapter.8.down.0.weight
text_prompt_learner.visual_adapter.8.down.0.bias
text_prompt_learner.visual_adapter.8.up.weight
text_prompt_learner.visual_adapter.8.up.bias
text_prompt_learner.visual_adapter.9.down.0.weight
text_prompt_learner.visual_adapter.9.down.0.bias
text_prompt_learner.visual_adapter.9.up.weight
text_prompt_learner.visual_adapter.9.up.bias
text_prompt_learner.visual_adapter.10.down.0.weight
text_prompt_learner.visual_adapter.10.down.0.bias
text_prompt_learner.visual_adapter.10.up.weight
text_prompt_learner.visual_adapter.10.up.bias
text_prompt_learner.visual_adapter.11.down.0.weight
text_prompt_learner.visual_adapter.11.down.0.bias
text_prompt_learner.visual_adapter.11.up.weight
text_prompt_learner.visual_adapter.11.up.bias
text_prompt_learner.visual_adapter.12.down.0.weight
text_prompt_learner.visual_adapter.12.down.0.bias
text_prompt_learner.visual_adapter.12.up.weight
text_prompt_learner.visual_adapter.12.up.bias
tot=126579840, train = 599424
===============================================
epoch = [1/1]loss = {'net': 5.227285661697388, 'acc': 0.4693333333333333}

***Validation***
udcdr == 0
Query:sketch; Gallery:real; Generalized:0

Query Emb Dim:torch.Size([9729, 512]); Gallery Emb Dim:torch.Size([24387, 512])
computing unormed situation
tensor(0.5752, device='cuda:1') tensor(0.5157, device='cuda:1')
computing normed situation
tensor(0.5839, device='cuda:1') tensor(0.5219, device='cuda:1')
un-norm situation:
learned: map: 0.5751739740371704, prec: 0.515727698802948
norm situation:
learned: map: 0.5838606953620911, prec: 0.5218567848205566
Query:sketch; Gallery:real; Generalized:1
