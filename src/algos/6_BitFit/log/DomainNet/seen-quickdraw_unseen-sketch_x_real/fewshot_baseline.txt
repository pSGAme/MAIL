================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
tot=126015776, train = 35360
===============================================
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([60, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([60, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([60, 512])
torch.Size([60, 300, 77, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([60, 512])
torch.Size([60, 300, 77, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=20, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 20
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([20, 512])
torch.Size([20, 300, 77, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=10, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 10
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([10, 512])
torch.Size([10, 300, 77, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([2, 512])
torch.Size([2, 300, 77, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
torch.Size([2, 512])
torch.Size([2, 300, 77, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([2, 512])
torch.Size([2, 300, 77, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
torch.Size([2, 512])
torch.Size([2, 300, 77, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([2, 512])
torch.Size([2, 300, 77, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
torch.Size([2, 512])
torch.Size([2, 300, 77, 512])
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([2, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([2, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
torch.Size([2, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
memory before:558415360 bytes
memory after:749502464 bytes
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
memory before:8698773504 bytes
memory after:8888934912 bytes
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
memory before:0.5200648307800293 GBs
memory after:0.698028564453125 GBs
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
memory before:8.101364135742188 GBs
memory after:8.278465747833252 GBs
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
memory before:0.5200648307800293 GBs
memory after:0.698028564453125 GBs
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
tensor(5.1262, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(4.7529, device='cuda:0', grad_fn=<NllLossBackward0>)
memory before:8.101364135742188 GBs
memory after:8.278465747833252 GBs
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
memory before:0.5200648307800293 GBs
memory after:0.698028564453125 GBs
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
memory before:0.5200648307800293 GBs
memory after:0.698028564453125 GBs
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
memory before:0.5200648307800293 GBs
memory after:0.698028564453125 GBs
torch.Size([77, 300, 512])
torch.Size([77, 300, 512])
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0015, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0015
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
[Train] Epoch: [1/1][100/6750]  Time 0.390 (0.401)  cls 10.6053 (11.3029)  contrastive 0.0000 (0.0000)  loss 10.6053 (11.3029)  
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0001, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0001
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0001, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0001
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0001, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0001
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
[Train] Epoch: [1/1][100/6750]  Time 0.388 (0.408)  cls 7.6597 (9.0881)  contrastive 0.0000 (0.0000)  loss 7.6597 (9.0881)  
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0001, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0001
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0001, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0001
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0001, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0001
batch_size = 60
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0001, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=30, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0001
batch_size = 30
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0001, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=15, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0001
batch_size = 15
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0001, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0001
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)
tensor(0., device='cuda:0', grad_fn=<AddBackward0>)
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
[Train] Epoch: [1/1][100/6750]  Time 0.389 (0.405)  cls 11.4145 (11.4119)  contrastive 0.0000 (0.0000)  loss 11.4145 (11.4119)  
[Train] Epoch: [1/1][200/6750]  Time 0.389 (0.397)  cls 11.3415 (11.4172)  contrastive 0.0000 (0.0000)  loss 11.3415 (11.4172)  
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
584277327872.0
84258336.0
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 1168.554655744 B
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 1168.554655744 B
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPS: 4.133742592 G
Params: 25.557032 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 2.946793472 G
Params: 59.061792 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 2.946793472 G
Params: 59.061792 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 2.946793472 G
Params: 59.061792 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 2.946760704 G
Params: 59.02848 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 2.946793472 G
Params: 59.061792 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 2.946793472 G
Params: 59.061792 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 2.946793472 G
Params: 59.061792 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 2.946793472 G
Params: 59.061792 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 460.2601472 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
torch.Size([300, 77, 512])
FLOPS: 460.2601472 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
torch.Size([300, 77, 512])
FLOPS: 576.52625408 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
torch.Size([300, 77, 512])
FLOPS: 460.2601472 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
torch.Size([300, 77, 512])
FLOPS: 522.268737536 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
torch.Size([300, 77, 512])
FLOPS: 336.242966528 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
torch.Size([300, 77, 512])
FLOPS: 126.963974144 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 584.277327872 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=1, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 1
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
[Train] Epoch: [1/1][100/7500]  Time 0.198 (0.212)  cls 4.9144 (5.2236)  contrastive 0.0000 (0.0000)  loss 4.9144 (5.2236)  
[Train] Epoch: [1/1][200/7500]  Time 0.200 (0.205)  cls 5.4378 (5.4730)  contrastive 0.0000 (0.0000)  loss 5.4378 (5.4730)  
[Train] Epoch: [1/1][300/7500]  Time 0.200 (0.203)  cls 5.6809 (5.5653)  contrastive 0.0000 (0.0000)  loss 5.6809 (5.5653)  
[Train] Epoch: [1/1][400/7500]  Time 0.199 (0.202)  cls 5.6798 (5.6001)  contrastive 0.0000 (0.0000)  loss 5.6798 (5.6001)  
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=1, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 1
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
FLOPS: 1168.554655744 G
Params: 84.258336 M
================Parameters Settings=================
Parameters:	Namespace(alpha=11.0, log_name='fewshot_baseline', visual='VPT', vptNumTokens=4, ctx_init='a photo of a', text='CoOp', textNumTokens=4, maple=1, maple_depth=1, maple_length=4, ivlp=0, optimizer='adam', l2_reg=0.0, epochs=1, lr=0.002, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=2, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.002
batch_size = 2
visual prompt numbers = 4
text prompt-setup = CoOp
text prompt numbers= 4
maple used？= 1
ivlp used？= 0
==================================================
======== Context-aware Simulator Learning Setup========
text_prompt_learner.ctx
text_prompt_learner.meta_net.linear1.weight
text_prompt_learner.meta_net.linear1.bias
text_prompt_learner.meta_net.linear2.weight
text_prompt_learner.meta_net.linear2.bias
text_encoder.text_projection
visual_encoder.proj
tot=126015776, train = 690720
===============================================
